{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971b3ead-ba32-4321-9fda-4120bd3fb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f766fb-529f-4fb2-98e2-1aa0c8b532fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_duration(duration_seconds):\n",
    "    s = duration_seconds % 60\n",
    "    duration_in_minutes = (duration_seconds - s) // 60\n",
    "    m = duration_in_minutes % 60\n",
    "    h = (duration_in_minutes - m) // 60\n",
    "\n",
    "    return f\"{h}h {m}m {s}s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8338d66-a246-4c95-9069-e38e8f6faa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.read_table(os.path.join(os.getcwd(), \"data\", \"x_train.txt\"), header=None, sep=\" \")\n",
    "y_train_df = pd.read_table(os.path.join(os.getcwd(), \"data\", \"y_train.txt\"), header=None)\n",
    "X_test_df = pd.read_table(os.path.join(os.getcwd(), \"data\", \"x_test.txt\"), header=None, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365d2315-2ad5-47ae-aaea-fb30a499add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_df.values\n",
    "X_scaled = StandardScaler().fit_transform(X_train)\n",
    "y_train = y_train_df.values.flatten()\n",
    "X_test = X_test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "993a960f-d408-45d0-af83-1fdc41e58789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lasso:\n",
    "    def __init__(self, X, y):\n",
    "        self.stdsc = StandardScaler().fit(X)\n",
    "        \n",
    "        self.X = self.stdsc.transform(X)\n",
    "        self.y = y\n",
    "        \n",
    "        self.best_C = None\n",
    "        self.best_features = None\n",
    "\n",
    "        return\n",
    "\n",
    "    def fit(self):\n",
    "        best_value = float(\"-inf\")\n",
    "        selected_features = np.arange(self.X.shape[1])\n",
    "        \n",
    "        for C in tqdm(np.linspace(1, 0.001, 1000)):\n",
    "            model = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", C=C).fit(self.X[:, selected_features], self.y)\n",
    "        \n",
    "            probabilities_of_label_1 = model.predict_proba(self.X[:, selected_features])[:, 1]\n",
    "            s = np.argsort(probabilities_of_label_1)\n",
    "        \n",
    "            selected_features = np.argwhere(model.coef_.flatten() != 0).flatten()\n",
    "        \n",
    "            reward = (np.round(probabilities_of_label_1[s[-1000:]]) == self.y[s[-1000:]]).sum() * 10\n",
    "            cost = len(selected_features) * 200\n",
    "        \n",
    "            value = reward - cost\n",
    "            if best_value < value:\n",
    "                best_value = value\n",
    "                \n",
    "                self.best_C = C\n",
    "                self.best_features = selected_features\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.stdsc.transform(X)\n",
    "        model = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", C=self.best_C).fit(self.X[:, self.best_features], self.y)\n",
    "\n",
    "        probabilities_of_label_1 = model.predict_proba(X[:, self.best_features])[:, 1]\n",
    "        s = np.argsort(probabilities_of_label_1)\n",
    "\n",
    "        return s[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cacc6001-cecf-4219-bde6-ed52ff16b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [06:56<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(X_train, y_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669d99de-9c2c-4a4b-ba2b-8efb39070326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.09599999999999997)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c0d829-a834-4601-b469-094a8cb33752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c48f7c42-9c06-487f-9b08-f88116cf3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lasso.best_features).to_csv(\"solutions/lasso_features_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "704c4afa-5ce3-45fd-ae1c-88594f5184ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1927, 4032, 2423, 1402, 2369,  631, 3581, 4640, 1668,  255,  386,\n",
       "       4419, 4153, 4187, 1910, 2394,  996, 1537, 2982, 4097, 3836,  800,\n",
       "       2667, 3205, 1761, 2126,  296, 2652,  889, 1212, 3595, 3873, 4403,\n",
       "       2419, 1101, 1114, 3361, 4136, 2780, 4673, 1704, 2869, 3941, 1338,\n",
       "       3330,  452, 2651, 3544, 4648, 2483, 1786, 3343, 2121, 2362,  311,\n",
       "       2189, 1782, 3174,  592, 4373,  364, 3767, 2857, 3810, 2257, 1980,\n",
       "       3240, 1060, 4086, 4070, 1878,  347, 3935, 3351, 1374, 4757, 1971,\n",
       "       3294, 3322, 4039, 2471, 1584, 3951, 1076, 1041, 1896, 3277, 2263,\n",
       "       1544, 2587, 4963, 3113,  470, 4990,   82,   33, 1226, 2855, 2361,\n",
       "       4929,  872, 2521,  335, 4299, 3846, 2447, 4707, 3871, 4949, 1746,\n",
       "       2961, 2681,  113, 1838, 4790, 2765, 1152, 2062,  790, 1488,  531,\n",
       "       1667,  632,  807, 1506, 2909, 1426, 3429, 3538, 2316, 2781,   94,\n",
       "        587, 2410,  602, 3893, 1570, 4714,  900, 2960, 3656, 2091, 2192,\n",
       "       3902, 1068, 1970, 2465, 2747, 3048, 3675, 1384,  963, 2383, 1030,\n",
       "         89, 1895, 2462, 2047, 4781, 3037, 4484, 1966,  671,  231,  104,\n",
       "       4124, 2039, 3857, 4548, 3827, 4869,  442,  487, 4388, 3888, 2026,\n",
       "       2138,  953, 1692, 3384, 2933,  554, 4688,  694,  712, 4814,  279,\n",
       "       3252, 2385, 3616, 2378, 4216, 3921, 3497, 1197,  903, 3864, 1703,\n",
       "       3712, 4349, 3465, 1419, 1185,   65,  265,  561, 3948, 2684,  208,\n",
       "       4126, 1345, 1565,   60, 2143, 2783,  318,  850, 1283,  764, 3450,\n",
       "       4809, 4372, 3977, 1753, 3417, 2488,  854, 3468, 3912,  955, 2737,\n",
       "       3778, 1549, 2628, 3279, 3372, 3689, 2480, 2043, 2499, 1120, 3602,\n",
       "       4801, 2412, 4017, 2725, 3579, 4876, 4472, 1414, 3116, 3803, 1278,\n",
       "        648, 4854,  420, 3194, 4663, 3027, 1974, 1092, 1591, 1247,  566,\n",
       "        576, 2918,  844, 3402, 2865,  283, 2001, 2273, 3426, 2622, 3363,\n",
       "       4821,  391, 2519, 4652,  431, 2337, 1737, 1745, 3092, 2239, 4807,\n",
       "       1632, 3128, 3727, 2390,  103, 1797,  707, 4210, 2331, 4078, 2349,\n",
       "       1415, 2641, 2484,  873, 4129, 3078, 1105, 3403, 2186, 2260, 2161,\n",
       "       4131, 1925, 1435, 1135, 3303, 1102, 1396, 4264, 2544, 2086, 2648,\n",
       "       1891, 2764,  687, 4255, 3423, 4608, 4277,  246, 3327, 2096, 2660,\n",
       "       4666, 4953, 2174, 1651, 4435,  839, 3949,  758,  859, 1640, 3796,\n",
       "       1349, 3282,  662, 3785, 2826, 1149, 2796, 4912, 1718, 4991,  901,\n",
       "       1873, 4837, 3618, 2008,  521, 4148, 3315, 4353, 4806, 3026,  212,\n",
       "       3536, 1554, 4491, 4883, 2125, 1187, 4523, 4710,   72, 2288, 1490,\n",
       "       3856, 3126, 4079, 1344, 1043, 4922,  372, 1983, 1541, 1614, 3259,\n",
       "        788, 4875, 3355,  617, 4230, 1898, 2004, 3360, 1460, 4338, 2372,\n",
       "       3467, 1874, 3726, 4981, 4386, 2721, 4892, 4737, 2344, 3301, 1116,\n",
       "       3038, 4873,   68, 4510, 1539, 4369, 1239, 4298, 2454, 4113, 1588,\n",
       "       1892, 4996, 3141, 1439, 4993, 3722, 1391, 4568, 1289, 1067, 1550,\n",
       "        273, 2103, 3001,  275, 3704, 4289, 3320, 4514, 2577,  894, 3440,\n",
       "        620, 3151, 3958, 2283, 2285,  708, 2294, 3576, 1610, 3149, 2560,\n",
       "       1300, 1879, 3879, 4941, 3626,  861, 2984, 2402, 4534,  653, 3998,\n",
       "       3870, 1774, 4552, 2287, 4693,  237, 2570, 2821, 4899, 3985,  581,\n",
       "       1315,  313, 1742, 4538, 2155, 3201, 4549, 2133,   93, 3597,  271,\n",
       "        836, 2514,  489, 4501, 4492,   97, 1008, 2005, 4535, 4365,  641,\n",
       "       1547, 1461,  319, 1331, 3052, 4760, 3505,  748, 4446, 2827,  369,\n",
       "       2279, 2912, 1991, 3243, 1930, 1238, 3170, 2657,  967, 4635, 4651,\n",
       "        734, 1555, 2233,  985, 3017, 3898,  394, 4545, 3989, 2042, 3906,\n",
       "       4920, 2509, 4586,  202, 2363,  683, 3032, 1407, 4751, 3441,  289,\n",
       "        875,  630, 3270, 2798, 1790, 4798, 1585, 3489, 1543, 1342, 2302,\n",
       "       4102, 1947, 3272, 3353, 1977, 2095,  485, 4443, 4475, 3537, 2374,\n",
       "       1254,  527, 4072, 1903, 4420, 4088, 4139, 4802, 4331, 1638,  685,\n",
       "       1888, 2167,  535, 1309, 3573,  331, 1724, 1497, 2755, 2635, 4882,\n",
       "       4159, 3583, 4831,  618, 2791, 3554, 2177, 2203, 1306,  696, 4143,\n",
       "        101, 4495, 2396, 2360, 3003, 2244, 1698, 1025, 4306, 3288, 2928,\n",
       "       3099, 1233, 3492, 4910, 3139,  726, 1093,   23, 1177, 4345,   84,\n",
       "       2116,  490, 2221, 3432, 2726, 4797, 3588, 1446, 4214, 4381,  667,\n",
       "       1722, 2014, 3953, 1700,  604, 4720, 3481,  555,  270, 3009,  961,\n",
       "       4539, 1984, 1199,   62, 1386,  433, 2723, 2859, 3458, 1218, 1577,\n",
       "       4425,  824, 4371, 2886, 1755,  467, 2554, 4050, 3858, 4997, 3859,\n",
       "       1709,  584, 2235, 4197,  132, 2825,  493, 2978, 1049, 2995, 2129,\n",
       "       1573, 2222, 2617, 1375, 2452, 2618, 4168, 1369, 3015, 2581, 2642,\n",
       "       4337, 1047,  673, 3832, 1559, 1079,  107, 3777, 3412, 1246, 1842,\n",
       "       4611, 2298, 4304, 2654, 3392, 4969, 3790, 4262, 3331, 4762, 2567,\n",
       "        693, 2604, 4056,  524,  108, 1938,  843, 3874, 4394, 2267, 4542,\n",
       "       4627, 3806, 1368, 4184, 2342, 1723,  574, 3841,   98, 4350,   36,\n",
       "       4566, 3444, 4617, 1491, 1672, 1180, 4141,  558, 4314,  278,  421,\n",
       "        698,  253, 2556, 4120, 4452, 1969, 3112, 4297, 3799, 1731, 2334,\n",
       "        451, 2634, 3965, 4601,  140, 1689, 3833,  791, 3939, 4018,  222,\n",
       "       1476, 3933, 3422, 3762, 2398, 1100, 1127, 4723, 2749, 1498, 2864,\n",
       "       1335, 1732, 4605, 2218, 4009, 4915, 3333, 4671, 1606,  432, 3485,\n",
       "        749, 3793, 2700, 2313, 3321,  474, 1469, 1826, 1356, 1077, 1525,\n",
       "       3608, 4163, 2470, 4411, 2243, 3335, 1841, 2949, 1256,  395, 2431,\n",
       "       4271, 3000, 3166, 1529, 4598, 2669, 1137,  131, 4780, 1825, 4952,\n",
       "       1561, 2292, 1003, 2195, 2496, 1890, 4859, 2328, 2699,  232, 2824,\n",
       "       2916, 4766, 3535, 2712, 2353, 3178, 2456, 1216, 3063, 4027, 4856,\n",
       "        920, 1428, 2029, 1907,  868, 3925, 2368, 3080, 3219, 2788,  549,\n",
       "        109, 4775, 4273, 4235,  882, 4123, 1243, 4320, 4619, 4895, 4745,\n",
       "       1711, 3743, 4290, 3524,  987, 2321, 2386, 1165, 4445, 2985, 4551,\n",
       "       3445, 4683, 4908, 1408,  149, 3526, 1493, 3356,  550, 3693, 1805,\n",
       "       2908, 1057, 2271,  163, 1286,   80, 2993,  207, 1094, 2211, 1777,\n",
       "       1170, 2020,  664,  492, 4519, 1611, 1320, 1053, 3483, 4826, 4470,\n",
       "       3954, 4429, 3439, 3521, 2997, 3312, 2031, 2620,  681, 2803, 3451,\n",
       "       4754, 1457, 3872, 1756,  129, 1474, 2424,   96, 3114, 3672, 1866,\n",
       "       4749,  415, 1868, 2489, 3198, 1830, 3070, 1872, 2707, 3825, 4550,\n",
       "       4093,  280,    2,  405, 4480, 4479,  512, 4880, 3182, 3283, 2481,\n",
       "       3774, 3120, 3383, 2612, 2689, 1734, 1534, 4956, 3147, 3784, 3942,\n",
       "       2576,  883, 3510, 4829, 3449, 2216,   79, 3375, 4008, 4192, 3115,\n",
       "        384, 4075,  254, 3654, 3250, 3020, 3571, 1622, 2983, 2822, 2656,\n",
       "       4344, 4109, 2268, 4068, 3509, 1288, 4430, 4674, 3447,  281, 1020,\n",
       "       3347, 4354, 3789, 2735, 2084, 1361, 3780, 3866, 2792, 4755])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ac6bb0-b514-4476-a968-b415ff6f527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lasso.predict(X_test)).to_csv(\"solutions/lasso_observations_predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8945bcf6-d81c-4464-b889-552fc3df85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA:\n",
    "    def __init__(self, X, y):\n",
    "        self.stdsc = StandardScaler().fit(X)\n",
    "        \n",
    "        self.X = self.stdsc.transform(X)\n",
    "        self.y = y\n",
    "        \n",
    "        self.target_indexes = np.argwhere(self.y == 1)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def generate_population(self, population_size):\n",
    "        return [np.random.choice(self.X.shape[1], np.random.randint(1, self.X.shape[1] + 1), False) for _ in range(population_size)]\n",
    "\n",
    "    def evaluate_features(self, features):\n",
    "        model = LogisticRegression(penalty=None).fit(self.X[:, features], self.y)\n",
    "\n",
    "        probabilities_of_label_1 = model.predict_proba(self.X[:, features])[:, 1]\n",
    "        s = np.argsort(probabilities_of_label_1)\n",
    "    \n",
    "        reward = (np.round(probabilities_of_label_1[s[-1000:]]) == self.y[s[-1000:]]).sum() * 10\n",
    "        cost = len(features) * 200\n",
    "        \n",
    "        return -(reward - cost), s[-1000:]\n",
    "\n",
    "    def cross_over(self, parent_a, parent_b):\n",
    "        all_indexes = np.unique(np.concatenate((parent_a,parent_b)))\n",
    "        \n",
    "        return (\n",
    "            np.random.choice(all_indexes, np.random.randint(1, len(all_indexes) + 1), False),\n",
    "            np.random.choice(all_indexes, np.random.randint(1, len(all_indexes) + 1), False)\n",
    "        )\n",
    "\n",
    "    def mutate(self, representative):\n",
    "        to_remove = np.random.choice(self.X.shape[1], np.random.randint(1, 5 + 1), False)\n",
    "        to_add = np.random.choice(self.X.shape[1], np.random.randint(1, 5 + 1), False)\n",
    "        \n",
    "        return np.unique(np.union1d(np.setdiff1d(representative, to_remove), to_add))\n",
    "\n",
    "    def run(self, population_size=100, number_of_generations=100, cross_over_prob=0.2, mutation_prob=0.2):\n",
    "        population = self.generate_population(population_size)\n",
    "    \n",
    "        for generation in tqdm(range(number_of_generations)):\n",
    "            ## cross-over\n",
    "            # calculate values of function to optimise\n",
    "            proximities = np.array([self.evaluate_features(features)[0] for features in population])\n",
    "            # and transform them into probabilities\n",
    "            probabilities = self.proximities2probabilities(proximities)\n",
    "            children = []\n",
    "            # try to perform cross-over population_size times\n",
    "            for _ in range(population_size):\n",
    "                # if cross-over chance is successful\n",
    "                if random.random() < cross_over_prob:\n",
    "                    # select two parents for cross-over\n",
    "                    parent_indexes = np.random.choice(len(population), 2, False, probabilities)\n",
    "                    # retrieve parents\n",
    "                    parent_a, parent_b = population[parent_indexes[0]], population[parent_indexes[1]]\n",
    "                    # perform cross-over\n",
    "                    child_a, child_b = self.cross_over(parent_a, parent_b)\n",
    "                    children.append(child_a)\n",
    "                    children.append(child_b)\n",
    "            \n",
    "            population.extend(children)\n",
    "            \n",
    "            ## mutation\n",
    "            # calculate values of function to optimise\n",
    "            proximities = np.array([self.evaluate_features(features)[0] for features in population])\n",
    "            # and transform them into probabilities\n",
    "            probabilities = self.proximities2probabilities(proximities)\n",
    "            mutated = []\n",
    "            # try to perform mutation population_size times\n",
    "            for _ in range(population_size):\n",
    "                # if mutation chance is successful\n",
    "                if random.random() < mutation_prob:\n",
    "                    # select one representative to be mutated\n",
    "                    index = np.random.choice(len(population), 1, False, probabilities)\n",
    "                    # retrieve representative\n",
    "                    representative = population[index[0]]\n",
    "                    # perform mutation\n",
    "                    mutant = self.mutate(representative)\n",
    "                    mutated.append(mutant)\n",
    "                    \n",
    "            population.extend(mutated)\n",
    "    \n",
    "            ## selection\n",
    "            # calculate values of function to optimise\n",
    "            proximities = np.array([self.evaluate_features(features)[0] for features in population])\n",
    "            # and transform them into probabilities\n",
    "            probabilities = self.proximities2probabilities(proximities)\n",
    "            # evaluate, how much is 10% of population_size\n",
    "            top_10_best_len = int(0.1 * population_size)\n",
    "            # get indexes of models from population sorted by values of optimised function\n",
    "            s = np.argsort(proximities)\n",
    "            # top 10% of population_size models are advancing to new generation by default\n",
    "            new_population = [population[idx] for idx in s[:top_10_best_len]]\n",
    "            # rest indexes select randomly from current population\n",
    "            pr = probabilities[s[top_10_best_len:]]\n",
    "            rest_indexes = np.random.choice(s[top_10_best_len:], population_size - top_10_best_len, False, pr / pr.sum())\n",
    "            # fill new_population up to population_size elements\n",
    "            new_population.extend([population[idx] for idx in rest_indexes])\n",
    "            # replace current population with new one\n",
    "            population = new_population\n",
    "    \n",
    "        return population\n",
    "\n",
    "    def predict(self, X, features):\n",
    "        X = self.stdsc.transform(X)\n",
    "        model = LogisticRegression(penalty=None).fit(self.X[:, features], self.y)\n",
    "        \n",
    "        probabilities_of_label_1 = model.predict_proba(X[:, features])[:, 1]\n",
    "        s = np.argsort(probabilities_of_label_1)\n",
    "        \n",
    "        return s[-1000:]\n",
    "\n",
    "    @staticmethod\n",
    "    def proximities2probabilities(proximities):\n",
    "        proximities = np.clip(proximities, -50, 50)\n",
    "        mods = np.exp(-proximities)\n",
    "    \n",
    "        return mods / mods.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14a14aae-c5f3-4450-a3f6-cc902df5b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:23<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "ga = GA(X_train, y_train)\n",
    "population = ga.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924e8789-060a-4379-a195-910912c831e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d73a401-c6c9-4d49-aad8-f96c82518afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(population[0]).to_csv(\"solutions/ga_features_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e11850d-cd46-40c6-ae5f-e9b0021c52db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2961, 1517, 3174, 1612, 2957, 2600, 2857, 3698,  104, 3544, 3551,\n",
       "       2126, 3361,  940, 1060, 2566, 3865, 2901, 1589, 3517, 2485, 2022,\n",
       "       1896, 3322, 3712, 2855, 1584, 4688, 4472, 3871, 4929, 3343, 3581,\n",
       "        452, 3530, 2488, 1878, 3602,  879, 4876, 4438, 2982,  962, 3873,\n",
       "        311, 3941,  103, 4714, 1374, 3586,  442, 2521, 1014, 2631, 2349,\n",
       "        274,  296,  591, 1360, 1668, 2667, 4869, 2063,  335, 1910, 1007,\n",
       "       3810, 3384, 1761, 4673, 2681, 2189, 3802, 4963, 1030,  364, 1226,\n",
       "       3372, 2651, 4388, 3685,  347, 3962, 4078, 2869,   65, 4136,  566,\n",
       "        592, 4070, 1402, 1576, 2471, 4097, 2462, 1338, 1992, 4233, 4893,\n",
       "       1786,  554, 2047,  694, 3027, 4124,  854,  632, 1746, 4086, 1838,\n",
       "       4707, 3689,  231,  171, 2737,  955,  470, 3616,  953, 1101, 2483,\n",
       "       1076,  996, 2519, 1966, 3252, 1185,  889, 1068, 4403, 2143, 2747,\n",
       "        872, 2465, 2263, 3538,   33, 1549, 3294, 2419, 2980, 4790, 3846,\n",
       "       1971, 2909, 3351, 2587, 2192, 2165, 3747, 1952, 2933, 2628,  487,\n",
       "        900,   82, 4372, 4809,  790, 3113, 4663, 4076, 1640, 4299, 3827,\n",
       "       1396, 2480, 4216,  265, 3675,  671, 4187, 1895,  531, 4548, 3048,\n",
       "        431, 3948, 2062, 2273, 1041, 1384, 2039,   60, 2960, 4373, 1278,\n",
       "       2865, 3579, 1980, 3092, 3429, 4854,  712, 2783, 1544, 3279, 2043,\n",
       "       2484,   94,  963, 3935,  208, 3403, 2091, 1488,  391,  283, 1632,\n",
       "       1345, 3977, 2447, 1506, 1753, 3656, 1419, 4990, 4807, 1974, 4949,\n",
       "       1797, 4801, 1415, 3902, 3402,  903, 2161, 4126, 2331, 2026, 4484,\n",
       "       1197, 1391,  844, 3864, 4039, 1703, 1874, 3857, 1692, 3618, 1102,\n",
       "       3141, 4781, 1426,  687,  587, 2385, 1667, 1247,  246,  420, 4131,\n",
       "       3037, 3116, 1092, 2378, 2826, 1435, 1983, 2423,  850, 3355, 2412,\n",
       "       4666,  807, 2641, 3426, 2725,  561, 1149, 1565, 3468, 3282, 4264,\n",
       "       1745, 3026, 4369, 1718, 3078, 4814,   89, 2337, 1925, 2174, 1539,\n",
       "       3778, 1187, 2765, 3194, 3856, 1591, 4349, 1120, 4608, 1541, 3726,\n",
       "        648, 3888, 1891, 4255, 3128, 3465, 1283, 1737,  602,  758, 3360,\n",
       "       4549, 1892, 3785, 4922, 2410, 1460, 3315, 1105, 1651, 3722, 4492,\n",
       "       3803, 2622,  859, 2096, 4875, 4148, 4821, 3450,  707,  901, 1898,\n",
       "       4353, 3989, 2390, 3423, 2260, 2499, 3921, 4953,  764,   97, 2239,\n",
       "       1414, 4534, 4491,  788, 1043,   68, 3497,  318, 2361, 1490, 4523,\n",
       "        576, 4837,  202, 3958, 3727, 2454, 2186, 3536, 1588, 3417, 2138,\n",
       "       2544, 4991, 2001, 2577, 3151, 4017, 2684, 4806, 1344, 3467, 1614,\n",
       "       2660, 2514, 3949, 3912, 4129, 1970, 4552, 3597, 4514,  521,  873,\n",
       "       4298, 2918, 4386, 1238,  839, 4435, 1067,  894, 3363, 4892, 2827,\n",
       "        708, 4538, 3441, 2086, 2657, 1135, 4910, 2288, 2570, 3796, 2796,\n",
       "        617, 2764, 2133, 1254, 1554, 2008, 3259, 3017, 2005,  372, 4210,\n",
       "       1239, 2554, 2648, 1550, 2125, 2509,   72, 4693, 4365, 1461,  394,\n",
       "       4912, 4981, 4338, 2374, 4277, 4710, 2344,  875, 2004, 3126, 4159,\n",
       "       4446, 1315, 3505, 2721, 1116, 4996, 4113, 4230, 1879, 3985,  581,\n",
       "       2283, 3303,  748, 2285, 1585, 4535, 2821, 3489, 1638,  662, 4652,\n",
       "       3032, 1008, 1349, 4883, 3906,  836, 2287,  313, 1289, 1873, 3573,\n",
       "       4510, 3320, 1331, 1790, 4882, 1742, 3704, 2103,  273, 3327, 4568,\n",
       "       1407,  275, 4993,  271, 4079, 4737, 2372, 3149, 2363, 1547, 3440,\n",
       "        369, 3038, 2791, 3870, 2294, 4545, 3001, 4798, 4760,  212, 2402,\n",
       "        489, 3458,  101, 3270, 3626, 4831, 3998, 3301, 2203, 3272, 2912,\n",
       "        641, 4873, 1342, 3554,  237, 3243, 1610, 2302, 1306, 2798, 2560,\n",
       "       1300, 1930, 3576, 2042, 2726, 3898, 1991,   93,  985, 3353, 3537,\n",
       "        653, 2360,  620, 1774, 1309, 4635, 1555, 3170, 1386,  535, 1199,\n",
       "       3052,  824,  527,  861, 3432, 2396, 3003, 1439, 4306,  319,  289,\n",
       "       4941, 1724, 2095, 1888, 3832, 2984,  630, 4289, 4050, 3879, 2279,\n",
       "       1446, 1573, 3099,  467, 2233, 4586, 2267, 4120, 4920,  683, 4381,\n",
       "       4443,   84, 2177, 3859, 4088, 2723, 2116, 2635, 1947, 2618, 4331,\n",
       "       4651, 2755, 2886, 2129, 4899, 4720,  107, 4501,  696, 4139, 3015,\n",
       "       3858, 1977, 4452, 4214, 3009, 4475, 1025, 1722, 1543,  604,  734,\n",
       "       4102,  618, 3201, 3139, 2859, 4072, 1233, 4197, 1709, 1755,  485,\n",
       "       2452, 2654, 2155, 3583, 4797, 3953, 1938, 1177, 2244, 2221, 4495,\n",
       "       2222,  132,  967, 4345, 4915, 1047,  685, 1903, 4371, 4802, 2825,\n",
       "       4420,  331, 4751,  667, 3588, 2556, 1246, 3288,  270,  961, 4425,\n",
       "        726, 1984, 3331, 1079, 1049, 2928, 2298, 4297, 4539,  490, 2014,\n",
       "       1375, 4168, 1497,  584, 2167, 4143, 3777, 3492,  108, 3412, 1700,\n",
       "       2642, 2604,  693, 2334, 1577, 3444,  524, 3481, 4542,   23, 1476,\n",
       "        278, 4617, 3833, 4350,  555, 1218, 1093, 3112, 2617, 2567, 4611,\n",
       "       1369,  432, 1559, 2995, 1698, 4018, 2235,   98, 3874, 4997, 3806,\n",
       "       1731, 3799,   62,  673, 3392, 3965, 4314,  493, 4566,  843, 3793,\n",
       "       1469, 2978, 4056,  574, 3485, 1368, 4009, 4184, 1127, 3762,   36,\n",
       "       1723, 4394, 4627, 4969, 1842, 4141, 2634, 3933, 3841, 3939, 2749,\n",
       "       4262, 4337,  222, 4271, 4762, 1525, 4601, 3790, 2342, 4605, 2699,\n",
       "       2218, 2581,  791, 4304, 2313,  433,  474,  253,  558, 1732,  395,\n",
       "       1180, 4952, 4671, 1491,  698, 2243,  140, 2700, 4859, 1137, 1077,\n",
       "       2195, 2949, 1969, 1672, 4780, 3321, 2496, 2292, 3422, 1100, 2353,\n",
       "       1256, 1826,  451,  868, 1498, 1689, 1335, 1841,  131, 4598, 1356,\n",
       "       4723, 2864, 4027, 1825, 4411,  421, 1561, 3925, 3335,  749, 2398,\n",
       "       3333,  232, 2669, 2824, 3608, 1907, 3080, 3535, 2368, 1003, 1711,\n",
       "        920, 1493, 3166, 3000, 4775, 2456, 2916, 4163, 2470, 2985, 4766,\n",
       "       1606, 4273, 3178, 2431, 3743, 2788, 4856, 2029,  149, 3063, 1529,\n",
       "       2328, 4123, 4895, 1428,  882, 1890, 4235, 1216,  549,  109, 1165,\n",
       "       2712, 4908,  987, 1805, 1243, 2386,  163, 4290, 2321, 3693, 1094,\n",
       "       1057, 1408, 4445, 1286, 3524, 3219, 4619, 4320, 2993, 4683, 3445,\n",
       "       4745,   80, 2908, 3356, 3521, 1320, 4429,  550, 2211, 1777, 2020,\n",
       "       3526, 2031, 4551, 1611, 3483, 2271,  207,  492, 2620, 2997, 3451,\n",
       "       1053, 1457,   96, 4470,  664, 4519, 1872, 3825, 1868, 3672, 4749,\n",
       "       1756, 3198, 3312, 3954,  883, 1170, 3114, 4826, 2803,  681, 1474,\n",
       "       4880, 1866,  405, 1830,    2, 4754, 3942, 3449,  129, 4550, 2707,\n",
       "        280, 3439, 2481, 2489, 4480, 2576, 2424, 3070,  512,  415, 3120,\n",
       "       4093,  384, 3872, 3147, 3784, 4008, 3774, 3283, 2612, 4956, 1734,\n",
       "       4075, 4479,   79, 3182, 4829, 3375, 2216, 2689, 3571, 1534, 3115,\n",
       "       3383, 3510, 4192, 3654, 1622,  254, 3020, 4344, 3250, 2268, 3509,\n",
       "       2983, 4109, 2656, 2822, 4068,  281, 1288, 4430, 3347, 1020, 4674,\n",
       "       3447, 2735, 4354, 3789, 1361, 2084, 3780, 3866, 4755, 2792])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga.predict(X_test, population[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "463dfd20-673d-4cf7-bb04-dec255e7bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ga.predict(X_test, population[0])).to_csv(\"solutions/ga_observations_predicted.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
