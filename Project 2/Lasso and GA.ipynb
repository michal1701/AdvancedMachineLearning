{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971b3ead-ba32-4321-9fda-4120bd3fb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f766fb-529f-4fb2-98e2-1aa0c8b532fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_duration(duration_seconds):\n",
    "    s = duration_seconds % 60\n",
    "    duration_in_minutes = (duration_seconds - s) // 60\n",
    "    m = duration_in_minutes % 60\n",
    "    h = (duration_in_minutes - m) // 60\n",
    "\n",
    "    return f\"{h}h {m}m {s}s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8338d66-a246-4c95-9069-e38e8f6faa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.read_table(os.path.join(os.getcwd(), \"data\", \"x_train.txt\"), header=None, sep=\" \")\n",
    "y_train_df = pd.read_table(os.path.join(os.getcwd(), \"data\", \"y_train.txt\"), header=None)\n",
    "X_test_df = pd.read_table(os.path.join(os.getcwd(), \"data\", \"x_test.txt\"), header=None, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365d2315-2ad5-47ae-aaea-fb30a499add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_df.values\n",
    "y_train = y_train_df.values.flatten()\n",
    "X_test = X_test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e3bede6-78f0-44bb-b056-d6822621f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_indexes = np.argwhere(y_train == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c54f81f-835a-4cde-ae37-af5658e68f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    2557\n",
       "1    2443\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c68e5-1774-495e-85a3-4c9d21448892",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_t = float(\"+inf\")\n",
    "best_C = None\n",
    "\n",
    "start = time.time()\n",
    "for C in tqdm(np.linspace(0.5, 0.001, 100)):\n",
    "    model = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", C=C).fit(X_train, y_train)\n",
    "\n",
    "    if model.predict(X_train)[target_indexes].sum() >= 1000:\n",
    "        t = len(np.argwhere(model.coef_ != 0))\n",
    "        \n",
    "        if t < best_t:\n",
    "            best_t = t\n",
    "            best_C = C\n",
    "end = time.time()\n",
    "print(f\"evaluation took {prettify_duration(end - start)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8945bcf6-d81c-4464-b889-552fc3df85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = StandardScaler().fit_transform(X)\n",
    "        self.y = y\n",
    "        self.target_indexes = np.argwhere(self.y == 1)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def generate_population(self, population_size):\n",
    "        return [np.random.choice(self.X.shape[1], np.random.randint(1, self.X.shape[1] + 1), False) for _ in range(population_size)]\n",
    "\n",
    "    def evaluate_features(self, features):\n",
    "        model = LogisticRegression(penalty=None).fit(self.X[:, features], self.y)\n",
    "\n",
    "        probabilities_of_label_1 = model.predict_proba(self.X[:, features])[:, 1]\n",
    "        s = np.argsort(probabilities_of_label_1)\n",
    "    \n",
    "        reward = (np.round(probabilities_of_label_1[s[-1000:]]) == self.y[s[-1000:]]).sum() * 10\n",
    "        cost = len(features) * 200\n",
    "        \n",
    "        return -(reward - cost)\n",
    "\n",
    "    def cross_over(self, parent_a, parent_b):\n",
    "        all_indexes = np.unique(np.concatenate((parent_a,parent_b)))\n",
    "        \n",
    "        return (\n",
    "            np.random.choice(all_indexes, np.random.randint(1, len(all_indexes) + 1), False),\n",
    "            np.random.choice(all_indexes, np.random.randint(1, len(all_indexes) + 1), False)\n",
    "        )\n",
    "\n",
    "    def mutate(self, representative):\n",
    "        to_remove = np.random.choice(self.X.shape[1], np.random.randint(1, 5 + 1), False)\n",
    "        to_add = np.random.choice(self.X.shape[1], np.random.randint(1, 5 + 1), False)\n",
    "        \n",
    "        return np.unique(np.union1d(np.setdiff1d(representative, to_remove), to_add))\n",
    "\n",
    "    def run(self, population_size=100, number_of_generations=100, cross_over_prob=0.2, mutation_prob=0.2):\n",
    "        population = self.generate_population(population_size)\n",
    "    \n",
    "        for generation in tqdm(range(number_of_generations)):\n",
    "            ## cross-over\n",
    "            # calculate values of function to optimise\n",
    "            proximities = np.array([self.evaluate_features(features) for features in population])\n",
    "            # and transform them into probabilities\n",
    "            probabilities = self.proximities2probabilities(proximities)\n",
    "            children = []\n",
    "            # try to perform cross-over population_size times\n",
    "            for _ in range(population_size):\n",
    "                # if cross-over chance is successful\n",
    "                if random.random() < cross_over_prob:\n",
    "                    # select two parents for cross-over\n",
    "                    parent_indexes = np.random.choice(len(population), 2, False, probabilities)\n",
    "                    # retrieve parents\n",
    "                    parent_a, parent_b = population[parent_indexes[0]], population[parent_indexes[1]]\n",
    "                    # perform cross-over\n",
    "                    child_a, child_b = self.cross_over(parent_a, parent_b)\n",
    "                    children.append(child_a)\n",
    "                    children.append(child_b)\n",
    "            \n",
    "            population.extend(children)\n",
    "            \n",
    "            ## mutation\n",
    "            # calculate values of function to optimise\n",
    "            proximities = np.array([self.evaluate_features(features) for features in population])\n",
    "            # and transform them into probabilities\n",
    "            probabilities = self.proximities2probabilities(proximities)\n",
    "            mutated = []\n",
    "            # try to perform mutation population_size times\n",
    "            for _ in range(population_size):\n",
    "                # if mutation chance is successful\n",
    "                if random.random() < mutation_prob:\n",
    "                    # select one representative to be mutated\n",
    "                    index = np.random.choice(len(population), 1, False, probabilities)\n",
    "                    # retrieve representative\n",
    "                    representative = population[index[0]]\n",
    "                    # perform mutation\n",
    "                    mutant = self.mutate(representative)\n",
    "                    mutated.append(mutant)\n",
    "                    \n",
    "            population.extend(mutated)\n",
    "    \n",
    "            ## selection\n",
    "            # calculate values of function to optimise\n",
    "            proximities = np.array([self.evaluate_features(features) for features in population])\n",
    "            # and transform them into probabilities\n",
    "            probabilities = self.proximities2probabilities(proximities)\n",
    "            # evaluate, how much is 10% of population_size\n",
    "            top_10_best_len = int(0.1 * population_size)\n",
    "            # get indexes of models from population sorted by values of optimised function\n",
    "            s = np.argsort(proximities)\n",
    "            # top 10% of population_size models are advancing to new generation by default\n",
    "            new_population = [population[idx] for idx in s[:top_10_best_len]]\n",
    "            # rest indexes select randomly from current population\n",
    "            pr = probabilities[s[top_10_best_len:]]\n",
    "            rest_indexes = np.random.choice(s[top_10_best_len:], population_size - top_10_best_len, False, pr / pr.sum())\n",
    "            # fill new_population up to population_size elements\n",
    "            new_population.extend([population[idx] for idx in rest_indexes])\n",
    "            # replace current population with new one\n",
    "            population = new_population\n",
    "    \n",
    "        return population\n",
    "\n",
    "    @staticmethod\n",
    "    def proximities2probabilities(proximities):\n",
    "        proximities = np.clip(proximities, -50, 50)\n",
    "        mods = np.exp(-proximities)\n",
    "    \n",
    "        return mods / mods.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a14aae-c5f3-4450-a3f6-cc902df5b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:12<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "ga = GA(X_train, y_train)\n",
    "population = ga.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "924e8789-060a-4379-a195-910912c831e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e11850d-cd46-40c6-ae5f-e9b0021c52db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(7210)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-ga.evaluate_features(population[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
